{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNLPVectors(filename):\n",
    "    file = 'nlp_data/' + filename + '.npy'\n",
    "    return np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLabels():\n",
    "    return loadNLPVectors(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOTH = 0\n",
    "TRAIN = 1\n",
    "TEST = 2\n",
    "def getData(nlp, tag = 0):\n",
    "    # 0 = train and test\n",
    "    # 1 = train only\n",
    "    # 2 = test only\n",
    "    X_train, X_test, y_train, y_test = train_test_split(nlp, \n",
    "                                                        labels, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 42, \n",
    "                                                        shuffle = True, \n",
    "                                                        stratify = labels)\n",
    "    train = [X_train, y_train]\n",
    "    test = [X_test, y_test]\n",
    "    if tag == BOTH:\n",
    "        return train, test\n",
    "    elif tag == TRAIN:\n",
    "        return train\n",
    "    else:\n",
    "        return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_array = \"feature_array_unigram\"\n",
    "bigram_array = \"feature_array_bigram\"\n",
    "tfidf_array = \"feature_array_tfidf\"\n",
    "wordvec_array = \"feature_array_word2vec\"\n",
    "unigram_reduced = \"reduced_unigram\"\n",
    "bigram_reduced = \"reduced_bigram\"\n",
    "tfidf_reduced = \"reduced_tfidf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = loadNLPVectors(unigram_array)\n",
    "bigram = loadNLPVectors(bigram_array)\n",
    "tfidf = loadNLPVectors(tfidf_array)\n",
    "word2vec = loadNLPVectors(wordvec_array)\n",
    "reduced_unigram = loadNLPVectors(unigram_reduced)\n",
    "reduced_bigram = loadNLPVectors(bigram_reduced)\n",
    "reduced_tfidf = loadNLPVectors(tfidf_reduced)\n",
    "labels = loadLabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni, test_uni = getData(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big, test_big = getData(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf, test_tfidf = getData(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec, test_vec = getData(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_runi, test_runi = getData(reduced_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rbig, test_rbig = getData(reduced_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rtfidf, test_rtfidf = getData(reduced_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_folders = ['unigram', 'bigram', 'tfidf', 'word2vec', 'reduced_unigram', 'reduced_bigram', 'reduced_tfidf']\n",
    "classifiers = ['rand_forest', 'log_reg', 'lin_reg', 'naive_bayes', 'svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(nlp_index, clf_index):\n",
    "    model_path = 'models/' + feature_folders[nlp_index] + '/' + classifiers[clf_index] + '.pkl'\n",
    "    model = joblib.load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Parameters to Tune for Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestHyperparameters():\n",
    "    \n",
    "    n_estimators = [int(x) for x in np.linspace(start = 2, stop = 200, num = 20)]\n",
    "    max_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "    max_depth.append(None)\n",
    "    max_features = [None, 'auto', 'sqrt', 'log2']\n",
    "    min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 100, num = 10)]\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 100, num = 10)]\n",
    "    \n",
    "    params = {'n_estimators': n_estimators, \n",
    "              'max_depth': max_depth,\n",
    "              'max_features': max_features,\n",
    "              'min_samples_split': min_samples_split, \n",
    "              'min_samples_leaf': min_samples_leaf}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegressionHyperparameters():\n",
    "    \n",
    "    penalty = ['l1', 'l2']\n",
    "    tol = [0.01, 0.001, 0.0001, .00001]\n",
    "    C = np.logspace(0, 4, 10)\n",
    "    max_iter = [int(x) for x in np.linspace(start = 50, stop = 200, num = 15)]\n",
    "    \n",
    "    params = {'penalty': penalty,\n",
    "              'tol': tol,\n",
    "              'C': C,\n",
    "              'max_iter': max_iter}\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupportVectorHyperparameters():\n",
    "    \n",
    "    C = np.logspace(0, 4, 10)\n",
    "    kernel = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "    tol = [0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    params = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'tol': tol}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayesHyperparameters():\n",
    "    \n",
    "    alpha = [x for x in range(0, 11)]\n",
    "    class_prior = [[.1, .9], [.2, .8], [.3, .7], [.4, .6]]\n",
    "    \n",
    "    params = {'alpha': alpha,\n",
    "              'class_prior': class_prior}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Untuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf = loadModel(2, 0)\n",
    "rf_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rtfidf = loadModel(6, 0)\n",
    "rf_rtfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_uni = loadModel(0, 1)\n",
    "lr_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_big = loadModel(1, 1)\n",
    "lr_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rbig = loadModel(5, 1)\n",
    "lr_rbig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big = loadModel(1, 3)\n",
    "nb_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_runi = loadModel(4, 4)\n",
    "svm_runi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model and Parameter Instances for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = RandomForestHyperparameters()\n",
    "lr_params = LogisticRegressionHyperparameters()\n",
    "nb_params = NaiveBayesHyperparameters()\n",
    "svm_params = SupportVectorHyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randGridOptimizer(clf, params, iterations, folds, train):\n",
    "    \n",
    "    tuningGrid = RandomizedSearchCV(estimator = clf,\n",
    "                                    param_distributions = params,\n",
    "                                    n_iter = iterations,\n",
    "                                    scoring = 'accuracy',\n",
    "                                    n_jobs = -1,\n",
    "                                    cv = folds,\n",
    "                                    verbose = 1,\n",
    "                                    random_state = 42)\n",
    "    \n",
    "    best_clf = tuningGrid.fit(train[0], train[1])\n",
    "    \n",
    "    return tuningGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest -TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf_grid = randGridOptimizer(rf_clf, rf_params, 30, 10, train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf_tuned = rf_tfidf_grid.best_estimator_\n",
    "rf_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Reduced TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rtfidf_grid = randGridOptimizer(rf_clf, rf_params, 30, 10, train_rtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rtfidf_tuned = rf_rtfidf_grid.best_estimator_\n",
    "rf_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_uni_grid = randGridOptimizer(lr_clf, lr_params, 30, 10, train_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_uni_tuned = lr_uni_grid.best_estimator_\n",
    "lr_uni_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_big_grid = randGridOptimizer(lr_clf, lr_params, 30, 10, train_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_big_tuned = lr_big_grid.best_estimator_\n",
    "lr_big_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Reduced Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rbig_grid = randGridOptimizer(lr_clf, lr_params, 30, 10, train_rbig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rbig_tuned = lr_rbig_grid.best_estimator_\n",
    "lr_rbig_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes - Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big_grid = randGridOptimizer(nb_clf, nb_params, 30, 10, train_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big_tuned = nb_big_grid.best_estimator_\n",
    "nb_big_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Reduced Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_runi_grid = randGridOptimizer(svm_clf, svm_params, 10, 5, train_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_runi_tuned = svm_runi_grid.best_estimator_\n",
    "svm_runi_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned vs Untuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(original, tuned, test, clf_name, nlp_name):\n",
    "    \n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    \n",
    "    y_pred = original.predict(X_test)\n",
    "    y_pred_t = tuned.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    acc_t = accuracy_score(y_test, y_pred_t)\n",
    "    roc_auc_t = roc_auc_score(y_test, y_pred_t)\n",
    "    f1_t = f1_score(y_test, y_pred_t)\n",
    "    precision_t = precision_score(y_test, y_pred_t)\n",
    "    recall_t = recall_score(y_test, y_pred_t)\n",
    "    \n",
    "    print('Untuned ' + clf_name + ' - ' + nlp_name + ' Metrics: ')\n",
    "    print(clf_name + ' Accuracy: ' + str(acc))\n",
    "    print(clf_name + ' ROC AUC Score: '+ str(roc_auc))\n",
    "    print(clf_name + ' F Score: ' + str(f1))\n",
    "    print(clf_name + ' Precision Score: ' + str(precision))\n",
    "    print(clf_name + ' Recall Score ' + str(recall))\n",
    "    print(\" \")\n",
    "    \n",
    "    print('Tuned ' + clf_name + ' - ' + nlp_name + ' Metrics: ')\n",
    "    print(clf_name + ' Accuracy: ' + str(acc_t))\n",
    "    print(clf_name + ' ROC AUC Score: '+ str(roc_auc_t))\n",
    "    print(clf_name + ' F Score: ' + str(f1_t))\n",
    "    print(clf_name + ' Precision Score: ' + str(precision_t))\n",
    "    print(clf_name + ' Recall Score ' + str(recall_t))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest TFIDF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(rf_tfidf, rf_tfidf_tuned, test_tfidf, 'Random Forest', 'TFIDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Reduced TFIDF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(rf_rtfidf, rf_rtfidf_tuned, test_rtfidf, 'Random Forest', 'Reduced TFIDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Unigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lr_uni, lr_uni_tuned, test_uni, 'Logistic Regression', 'Unigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Bigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lr_big, lr_big_tuned, test_big, 'Logistic Regression', 'Bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Reduced Bigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lr_rbig, lr_rbig_tuned, test_rbig, 'Logistic Regression', 'Reduced Bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Bigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(nb_big, nb_big_tuned, test_big, 'Naive Bayes', 'Bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Reduced Unigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(svm_runi, svm_runi_tuned, test_runi, 'SVM', 'Reduced Unigram')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
