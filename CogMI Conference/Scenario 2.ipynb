{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNLP(folder, name):\n",
    "    file = 'nlp/scenario_2/%s/%s.npy' % (folder, name)\n",
    "    return np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(folder):\n",
    "    X_train = loadNLP(folder, 'train')\n",
    "    y_train = loadNLP('labels', 'train')\n",
    "    \n",
    "    X_test = loadNLP(folder, 'test')\n",
    "    y_test = loadNLP('labels', 'test')\n",
    "    \n",
    "    train = [X_train, y_train]\n",
    "    test = [X_test, y_test]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni, test_uni = loadData('unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfu, test_tfu = loadData('unigram_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big, test_big = loadData('bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfb, test_tfb = loadData('bigram_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_runi, test_runi = loadData('reduced_unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rtfu, test_rtfu = loadData('reduced_unigram_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rbig, test_rbig = loadData('reduced_bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rtfb, test_rtfb = loadData('reduced_bigram_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Machine Learning Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genClassifiers():\n",
    "\n",
    "    classifiers = [LogisticRegression(), RandomForestClassifier()]\n",
    "    names = ['Logistic Regression', 'Random Forest']\n",
    "    \n",
    "    return classifiers, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalClassifiers(train, test):\n",
    "    \n",
    "    clf_array, clf_names = genClassifiers()\n",
    "    \n",
    "    X_train = train[0]\n",
    "    y_train = train[1]\n",
    "    \n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    \n",
    "    for i in range(0, len(clf_array)):\n",
    "        start = time.time()\n",
    "        clf_array[i].fit(X_train, y_train)\n",
    "        end = time.time() - start\n",
    "        \n",
    "        y_pred = clf_array[i].predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        f_score = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "\n",
    "        print(clf_names[i] + ': Completed in ' + str(end) + ' seconds')\n",
    "        print(clf_names[i] + ' Accuracy: ' + str(accuracy))\n",
    "        print(clf_names[i] + ' ROC AUC Score: ' + str(roc_auc))\n",
    "        print(clf_names[i] + ' F Score: ' + str(f_score))\n",
    "        print(clf_names[i] + ' Precision: ' + str(precision))\n",
    "        print(clf_names[i] + ' Recall: ' + str(recall))\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_uni, test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram-Tfidf Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_tfu, test_tfu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_big, test_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram-Tfidf Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_tfb, test_tfb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Unigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_runi, test_runi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Unigram-Tfidf Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_rtfu, test_rtfu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Bigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_rbig, test_rbig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Bigram-Tfidf Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalClassifiers(train_rtfb, test_rtfb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN(train, test, iterations = 50, early_stop = False, info = 0):\n",
    "    X_train = train[0]\n",
    "    y_train = train[1]\n",
    "    \n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    \n",
    "    dim = len(X_train[0])\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    if dim >= 40000:\n",
    "        model.add(layers.Dense(500, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu', input_shape = (dim,)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(128, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(32, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(4, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu'))\n",
    "    elif dim >= 9000:\n",
    "        model.add(layers.Dense(200, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu', input_shape = (dim,)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(64, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(4, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu'))        \n",
    "    elif dim >= 1000:\n",
    "        model.add(layers.Dense(100, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu', input_shape = (dim,)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(16, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu'))\n",
    "    else:\n",
    "        model.add(layers.Dense(16, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu', input_shape = (dim,)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(4, kernel_regularizer = l2(.001),\n",
    "                               activation = 'relu', input_shape = (dim, )))\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    callback = [EarlyStopping(monitor = 'val_loss', min_delta = .0001)]\n",
    "    if early_stop:\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            epochs = iterations,\n",
    "                            verbose = info,\n",
    "                            batch_size = 128,\n",
    "                            callbacks = callback,\n",
    "                            validation_data = (X_test, y_test))\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            epochs = iterations,\n",
    "                            verbose = info,\n",
    "                            batch_size = 128,\n",
    "                            validation_data = (X_test, y_test))\n",
    "        \n",
    "    end = time.time() - start\n",
    "    \n",
    "    test_vals = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(\"Training Time:  \", end)\n",
    "    print(\"Model Loss:     \", test_vals[0])\n",
    "    print(\"Model Accuracy: \", test_vals[1])\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFigures(hist, epoch_range):\n",
    "    \n",
    "    training_loss = hist.history['loss']\n",
    "    training_acc = hist.history['accuracy']\n",
    "    \n",
    "    validation_loss = hist.history['val_loss']\n",
    "    validation_acc = hist.history['val_accuracy']\n",
    "    \n",
    "    epochs = range(1, epoch_range + 1)\n",
    "    \n",
    "    f = plt.figure(1)\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.plot(epochs, training_loss, 'r', label = 'Training Loss')\n",
    "    plt.plot(epochs, validation_loss, 'b', label = 'Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    g = plt.figure(2)\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(epochs, training_acc, 'r', label = 'Training Acc')\n",
    "    plt.plot(epochs, validation_acc, 'b', label = 'Validation Acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, history, test, name):\n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    epoch_range = len(history.history['loss'])\n",
    "    \n",
    "    pred_sigmoid = model.predict(X_test)\n",
    "    pred = []\n",
    "    for p in pred_sigmoid:\n",
    "        if p < .5:\n",
    "            pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    y_pred = np.asarray(pred)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    f = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(name + ' Evaluation: ')\n",
    "    print('Accuracy:       ', acc)\n",
    "    print('ROC AUC Score:  ', roc_auc)\n",
    "    print('F1 Score:       ', f)\n",
    "    print('Precision:      ', precision)\n",
    "    print('Recall:         ', recall)\n",
    "    \n",
    "    plotFigures(history, epoch_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_uni, hist_uni = DNN(train_uni, test_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_tfu, hist_tfu = DNN(train_tfu, test_tfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_big, hist_big = DNN(train_big, test_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_tfb, hist_tfb = DNN(train_tfb, test_tfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_runi, hist_runi = DNN(train_runi, test_runi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_rtfu, hist_rtfu = DNN(train_rtfu, test_rtfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_rbig, hist_rbig = DNN(train_rbig, test_rbig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_rtfb, hist_rtfb = DNN(train_rtfb, test_rtfb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_uni, hist_uni, test_uni, 'DNN Unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_tfu, hist_tfu, test_tfu, 'DNN Unigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_big, hist_big, test_big, 'DNN Bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_tfb, hist_tfb, test_tfb, 'DNN Bigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_runi, hist_runi, test_runi, 'DNN Reduced Unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_rtfu, hist_rtfu, test_rtfu, 'DNN Reduced Unigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_rbig, hist_rbig, test_rbig, 'DNN Reduced Bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_rtfb, hist_rtfb, test_rtfb, 'DNN Reduced Bigram-Tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks - Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_uni_s, hist_uni_s = DNN(train_uni, test_uni, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_tfu_s, hist_tfu_s = DNN(train_tfu, test_tfu, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_big_s, hist_big_s = DNN(train_big, test_big, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_tfb_s, hist_tfb_s = DNN(train_tfb, test_tfb, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_runi_s, hist_runi_s = DNN(train_runi, test_runi, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_rtfu_s, hist_rtfu_s = DNN(train_rtfu, test_rtfu, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_rbig_s, hist_rbig_s = DNN(train_rbig, test_rbig, early_stop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_rtfb_s, hist_rtfb_s = DNN(train_rtfb, test_rtfb, early_stop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Neural Networks - Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_uni_s, hist_uni_s, test_uni, 'DNN Early Stop Unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_tfu_s, hist_tfu_s, test_tfu, 'DNN Early Stop Unigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_big_s, hist_big_s, test_big, 'DNN Early Stop Bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_tfb_s, hist_tfb_s, test_tfb, 'DNN Early Stop Bigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_runi_s, hist_runi_s, test_runi, 'DNN Early Stop Reduced Unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_rtfu_s, hist_rtfu_s, test_rtfu, 'DNN Early Stop Reduced Unigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_rbig_s, hist_rbig_s, test_rbig, 'DNN Early Stop Reduced Bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dnn_rtfb_s, hist_rtfb_s, test_rtfb, 'DNN Early Stop Reduced Bigram-Tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
