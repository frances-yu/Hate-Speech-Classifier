{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(filename):\n",
    "    file = filename\n",
    "    if '.csv' not in filename:\n",
    "        file += '.csv'\n",
    "    data = pd.read_csv(file, encoding = 'ISO-8859-1')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNLPVectors(filename):\n",
    "    file = 'nlp_data/' + filename + '.npy'\n",
    "    return np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLabels():\n",
    "    return loadNLPVectors(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"binary_classification\"\n",
    "data = loadCSV(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_array = \"feature_array_unigram\"\n",
    "bigram_array = \"feature_array_bigram\"\n",
    "tfidf_array = \"feature_array_tfidf\"\n",
    "wordvec_array = \"feature_array_word2vec\"\n",
    "unigram_reduced = \"reduced_unigram\"\n",
    "bigram_reduced = \"reduced_bigram\"\n",
    "tfidf_reduced = \"reduced_tfidf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genClassifiers(neg = False, filter = []):\n",
    "    svm_clf = SVC(probability = True)\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    log_clf = LogisticRegression()\n",
    "    lin_clf = LinearRegression()\n",
    "    \n",
    "    classifiers = [rf_clf, log_clf, lin_clf]\n",
    "    names = ['Random Forest', 'Logistic Regression', 'Linear Regression']\n",
    "    if not neg:\n",
    "        classifiers.append(MultinomialNB())\n",
    "        names.append('Naive Bayes')\n",
    "        \n",
    "    classifiers.append(svm_clf)\n",
    "    names.append('SVM')\n",
    "    \n",
    "    filtered_classifiers = []\n",
    "    filtered_names = []\n",
    "    for i in range(0, len(classifiers)):\n",
    "        if i not in filter:\n",
    "            filtered_classifiers.append(classifiers[i])\n",
    "            filtered_names.append(names[i])\n",
    "            \n",
    "    return filtered_classifiers, filtered_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(nlp):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(nlp, \n",
    "                                                        labels, \n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state = 42, \n",
    "                                                        shuffle = True, \n",
    "                                                        stratify = labels)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf_array, clf_names, nlp):\n",
    "    X_train, X_test, y_train, y_test = dataSplit(nlp)\n",
    "    for i in range(0, len(clf_array)):\n",
    "        start = time.time()\n",
    "        clf_array[i].fit(X_train, y_train)\n",
    "        end = time.time() - start\n",
    "        \n",
    "        y_pred = clf_array[i].predict(X_test)\n",
    "        \n",
    "        print(clf_names[i] + ': Completed in ' + str(end) + ' seconds')\n",
    "        if clf_names[i] == 'Linear Regression':\n",
    "            r2 = clf_array[i].score(X_test, y_test)\n",
    "            print(clf_names[i] + ' R^2 Score: ' + str(r2))\n",
    "        else:\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            f_score = f1_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            print(clf_names[i] + ' Accuracy: ' + str(accuracy))\n",
    "            print(clf_names[i] + ' ROC AUC Score: ' + str(roc_auc))\n",
    "            print(clf_names[i] + ' F Score: ' + str(f_score))\n",
    "            print(clf_names[i] + ' Precision: ' + str(precision))\n",
    "            print(clf_names[i] + ' Recall: ' + str(recall))\n",
    "        print(\" \")\n",
    "        \n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = loadNLPVectors(unigram_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = loadNLPVectors(bigram_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = loadNLPVectors(tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = loadNLPVectors(wordvec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_unigram = loadNLPVectors(unigram_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_bigram = loadNLPVectors(bigram_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tfidf = loadNLPVectors(tfidf_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = loadLabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced_TFIDF Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tfidf_clf, clf_names = genClassifiers(neg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 1.3704018592834473 seconds\n",
      "Random Forest Accuracy: 0.8673587081891581\n",
      "Random Forest ROC AUC Score: 0.8659922209376764\n",
      "Random Forest F Score: 0.8565488565488565\n",
      "Random Forest Precision: 0.9050966608084359\n",
      "Random Forest Recall: 0.8129439621152328\n",
      " \n",
      "Logistic Regression: Completed in 0.2952888011932373 seconds\n",
      "Logistic Regression Accuracy: 0.9015763168012303\n",
      "Logistic Regression ROC AUC Score: 0.8997667701271701\n",
      "Logistic Regression F Score: 0.8914334181509754\n",
      "Logistic Regression Precision: 0.9633363886342805\n",
      "Logistic Regression Recall: 0.829518547750592\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: Completed in 0.24732017517089844 seconds\n",
      "Linear Regression R^2 Score: 0.4933942699678997\n",
      " \n",
      "SVM: Completed in 170.67447996139526 seconds\n",
      "SVM Accuracy: 0.6197616301422529\n",
      "SVM ROC AUC Score: 0.6097277919840395\n",
      "SVM F Score: 0.36069812540400775\n",
      "SVM Precision: 0.9964285714285714\n",
      "SVM Recall: 0.2202052091554854\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_rtfidf, y_rtfidf = evaluate(reduced_tfidf_clf, clf_names, reduced_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced_Unigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_unigram_clf, clf_names = genClassifiers(neg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 1.428300142288208 seconds\n",
      "Random Forest Accuracy: 0.8696655132641292\n",
      "Random Forest ROC AUC Score: 0.8682807372951251\n",
      "Random Forest F Score: 0.8589263420724095\n",
      "Random Forest Precision: 0.9084507042253521\n",
      "Random Forest Recall: 0.8145224940805051\n",
      " \n",
      "Logistic Regression: Completed in 0.45800113677978516 seconds\n",
      "Logistic Regression Accuracy: 0.9115724721261054\n",
      "Logistic Regression ROC AUC Score: 0.9101659706847445\n",
      "Logistic Regression F Score: 0.9040867389491243\n",
      "Logistic Regression Precision: 0.9584438549955792\n",
      "Logistic Regression Recall: 0.8555643251775849\n",
      " \n",
      "Linear Regression: Completed in 0.2010180950164795 seconds\n",
      "Linear Regression R^2 Score: 0.5372764672085395\n",
      " \n",
      "SVM: Completed in 102.91931104660034 seconds\n",
      "SVM Accuracy: 0.8746635909265668\n",
      "SVM ROC AUC Score: 0.8717658731802213\n",
      "SVM F Score: 0.8551111111111112\n",
      "SVM Precision: 0.9786368260427264\n",
      "SVM Recall: 0.7592738752959748\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_runi, y_runi = evaluate(reduced_unigram_clf, clf_names, reduced_unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced_Bigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_bigram_clf, clf_names = genClassifiers(neg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 2.1718571186065674 seconds\n",
      "Random Forest Accuracy: 0.8612072279892349\n",
      "Random Forest ROC AUC Score: 0.859717733871817\n",
      "Random Forest F Score: 0.849143334726285\n",
      "Random Forest Precision: 0.9023090586145648\n",
      "Random Forest Recall: 0.8018942383583267\n",
      " \n",
      "Logistic Regression: Completed in 1.2169358730316162 seconds\n",
      "Logistic Regression Accuracy: 0.9142637447135717\n",
      "Logistic Regression ROC AUC Score: 0.913186066792965\n",
      "Logistic Regression F Score: 0.9082682023858494\n",
      "Logistic Regression Precision: 0.9484536082474226\n",
      "Logistic Regression Recall: 0.8713496448303079\n",
      " \n",
      "Linear Regression: Completed in 0.8626759052276611 seconds\n",
      "Linear Regression R^2 Score: 0.5708337151892493\n",
      " \n",
      "SVM: Completed in 262.4953439235687 seconds\n",
      "SVM Accuracy: 0.8469819300269127\n",
      "SVM ROC AUC Score: 0.8432333754196304\n",
      "SVM F Score: 0.8162511542012927\n",
      "SVM Precision: 0.9833147942157954\n",
      "SVM Recall: 0.6977111286503551\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_rbig, y_rbig = evaluate(reduced_bigram_clf, clf_names, reduced_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_clf, clf_names = genClassifiers(neg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 0.8266351222991943 seconds\n",
      "Random Forest Accuracy: 0.5151864667435602\n",
      "Random Forest ROC AUC Score: 0.5119212295983027\n",
      "Random Forest F Score: 0.4362986142154671\n",
      "Random Forest Precision: 0.5030927835051546\n",
      "Random Forest Recall: 0.3851617995264404\n",
      " \n",
      "Logistic Regression: Completed in 0.05595803260803223 seconds\n",
      "Logistic Regression Accuracy: 0.512879661668589\n",
      "Logistic Regression ROC AUC Score: 0.5\n",
      "Logistic Regression F Score: 0.0\n",
      "Logistic Regression Precision: 0.0\n",
      "Logistic Regression Recall: 0.0\n",
      " \n",
      "Linear Regression: Completed in 0.04768204689025879 seconds\n",
      "Linear Regression R^2 Score: -0.005723566339111308\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Completed in 71.16608691215515 seconds\n",
      "SVM Accuracy: 0.512879661668589\n",
      "SVM ROC AUC Score: 0.5\n",
      "SVM F Score: 0.0\n",
      "SVM Precision: 0.0\n",
      "SVM Recall: 0.0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_vec, y_vec = evaluate(word2vec_clf, clf_names, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw TFIDF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_clf, clf_names = genClassifiers(filter = [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 12.608357906341553 seconds\n",
      "Random Forest Accuracy: 0.8954248366013072\n",
      "Random Forest ROC AUC Score: 0.8939085114112242\n",
      "Random Forest F Score: 0.8860971524288107\n",
      "Random Forest Precision: 0.943800178412132\n",
      "Random Forest Recall: 0.835043409629045\n",
      " \n",
      "Logistic Regression: Completed in 0.22922515869140625 seconds\n",
      "Logistic Regression Accuracy: 0.9042675893886967\n",
      "Logistic Regression ROC AUC Score: 0.9026283030544713\n",
      "Logistic Regression F Score: 0.895157894736842\n",
      "Logistic Regression Precision: 0.9593862815884476\n",
      "Logistic Regression Recall: 0.8389897395422258\n",
      " \n",
      "Naive Bayes: Completed in 0.48565196990966797 seconds\n",
      "Naive Bayes Accuracy: 0.851595540176855\n",
      "Naive Bayes ROC AUC Score: 0.8517744876575131\n",
      "Naive Bayes F Score: 0.849336455893833\n",
      "Naive Bayes Precision: 0.8401544401544402\n",
      "Naive Bayes Recall: 0.8587213891081295\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_tfidf, y_tfidf = evaluate(tfidf_clf, clf_names, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Unigram Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_clf, clf_names = genClassifiers(filter = [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 12.03729510307312 seconds\n",
      "Random Forest Accuracy: 0.889273356401384\n",
      "Random Forest ROC AUC Score: 0.8882286362738127\n",
      "Random Forest F Score: 0.8817733990147782\n",
      "Random Forest Precision: 0.9187339606501284\n",
      "Random Forest Recall: 0.8476716653512234\n",
      " \n",
      "Logistic Regression: Completed in 1.489346981048584 seconds\n",
      "Logistic Regression Accuracy: 0.9154171472510573\n",
      "Logistic Regression ROC AUC Score: 0.9144294269597639\n",
      "Logistic Regression F Score: 0.9098360655737705\n",
      "Logistic Regression Precision: 0.9462915601023018\n",
      "Logistic Regression Recall: 0.8760852407261247\n",
      " \n",
      "Naive Bayes: Completed in 1.4319968223571777 seconds\n",
      "Naive Bayes Accuracy: 0.8650519031141869\n",
      "Naive Bayes ROC AUC Score: 0.8655470015584157\n",
      "Naive Bayes F Score: 0.8646355572695719\n",
      "Naive Bayes Precision: 0.8453996983408748\n",
      "Naive Bayes Recall: 0.8847671665351223\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_uni, y_uni = evaluate(unigram_clf, clf_names, unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Bigram Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_clf, clf_names = genClassifiers(filter = [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 84.75579595565796 seconds\n",
      "Random Forest Accuracy: 0.8904267589388697\n",
      "Random Forest ROC AUC Score: 0.8889566661026235\n",
      "Random Forest F Score: 0.880902632678646\n",
      "Random Forest Precision: 0.9360568383658969\n",
      "Random Forest Recall: 0.8318863456985004\n",
      " \n",
      "Logistic Regression: Completed in 27.815634965896606 seconds\n",
      "Logistic Regression Accuracy: 0.9150326797385621\n",
      "Logistic Regression ROC AUC Score: 0.9139356919803714\n",
      "Logistic Regression F Score: 0.9090160559901194\n",
      "Logistic Regression Precision: 0.9500860585197934\n",
      "Logistic Regression Recall: 0.8713496448303079\n",
      " \n",
      "Naive Bayes: Completed in 28.647745847702026 seconds\n",
      "Naive Bayes Accuracy: 0.8669742406766628\n",
      "Naive Bayes ROC AUC Score: 0.8677580112863853\n",
      "Naive Bayes F Score: 0.8680396643783371\n",
      "Naive Bayes Precision: 0.8398523985239852\n",
      "Naive Bayes Recall: 0.8981846882399369\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_big, y_big = evaluate(bigram_clf, clf_names, bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "folderpath = path + \"/models\"\n",
    "os.mkdir(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModels(features, feature_names, classifiers, X_array, y_array):\n",
    "    for i in range(0, len(features)):\n",
    "        feat = features[i]\n",
    "        os.mkdir(folderpath + feature_names[i])\n",
    "        for j in range(0, len(classifiers)):\n",
    "            clas = feat[j]\n",
    "            filepath = folderpath + feature_names[i] + classifiers[j] + \".pkl\"\n",
    "            joblib.dump(clas, filepath)\n",
    "            \n",
    "            # test to see if models correctly saved\n",
    "            clas_load = joblib.load(filepath)\n",
    "            X = X_array[i]\n",
    "            y = y_array[i]\n",
    "            \n",
    "            assert clas.score(X, y) == clas_load.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list1 = [reduced_tfidf_clf, reduced_unigram_clf, reduced_bigram_clf, word2vec_clf]\n",
    "f_list2 = [tfidf_clf, unigram_clf, bigram_clf]\n",
    "\n",
    "fname_list1 = [\"/reduced_tfidf\", \"/reduced_unigram\", \"/reduced_bigram\", \"/word2vec\"]\n",
    "fname_list2 = [\"/tfidf\", \"/unigram\", \"/bigram\"]\n",
    "\n",
    "c_list1 = [\"/rand_forest\", \"/log_reg\", \"/lin_reg\", \"/svm\"]\n",
    "c_list2 = [\"/rand_forest\", \"/log_reg\", \"/naive_bayes\"]\n",
    "\n",
    "fx_list1 = [x_rtfidf, x_runi, x_rbig, x_vec]\n",
    "fy_list1 = [y_rtfidf, y_runi, y_rbig, y_vec]\n",
    "\n",
    "fx_list2 = [x_tfidf, x_uni, x_big]\n",
    "fy_list2 = [y_tfidf, y_uni, y_big]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModels(f_list1, fname_list1, c_list1, fx_list1, fy_list1)\n",
    "saveModels(f_list2, fname_list2, c_list2, fx_list2, fy_list2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
