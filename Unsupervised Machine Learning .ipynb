{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNLPVectors(filename):\n",
    "    file = 'nlp_data/' + filename + '.npy'\n",
    "    return np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLabels():\n",
    "    return loadNLPVectors(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def genData(nlp):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(nlp, labels,\n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 42,\n",
    "                                                        shuffle = True,\n",
    "                                                        stratify = labels)\n",
    "    \n",
    "    train = [X_train, y_train]\n",
    "    test = [X_test, y_test]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_array = \"feature_array_unigram\"\n",
    "bigram_array = \"feature_array_bigram\"\n",
    "tfidf_array = \"feature_array_tfidf\"\n",
    "wordvec_array = \"feature_array_word2vec\"\n",
    "unigram_reduced = \"reduced_unigram\"\n",
    "bigram_reduced = \"reduced_bigram\"\n",
    "tfidf_reduced = \"reduced_tfidf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = loadNLPVectors(unigram_array)\n",
    "bigram = loadNLPVectors(bigram_array)\n",
    "tfidf = loadNLPVectors(tfidf_array)\n",
    "word2vec = loadNLPVectors(wordvec_array)\n",
    "reduced_unigram = loadNLPVectors(unigram_reduced)\n",
    "reduced_bigram = loadNLPVectors(bigram_reduced)\n",
    "reduced_tfidf = loadNLPVectors(tfidf_reduced)\n",
    "labels = loadLabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni, test_uni = genData(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big, test_big = genData(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf, test_tfidf = genData(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec, test_vec = genData(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_runi, test_runi = genData(reduced_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rbig, test_rbig = genData(reduced_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rtfidf, test_rtfidf = genData(reduced_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kCluster(train, verbose = 0):\n",
    "    cluster = KMeans(n_clusters = 2, verbose = verbose)\n",
    "    start = time.time()\n",
    "    cluster.fit(train[0], train[1])\n",
    "    end = time.time() - start\n",
    "    print('Training Time: ' + str(end))\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideTestData(test):\n",
    "    X = test[0]\n",
    "    y = test[1]\n",
    "    \n",
    "    neutral_array = []\n",
    "    hate_array = []\n",
    "    \n",
    "    for i in range(0, len(y)):\n",
    "        if y[i] == 0:\n",
    "            neutral_array.append(X[i])\n",
    "        elif y[i] == 1:\n",
    "            hate_array.append(X[i])\n",
    "    \n",
    "    neutral = np.asarray(neutral_array)\n",
    "    hate = np.asarray(hate_array)\n",
    "    \n",
    "    return neutral, hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClusterAvg(cluster_pred):\n",
    "    total = len(cluster_pred)\n",
    "    count_0 = 0\n",
    "    count_1 = 0\n",
    "    for i in range(0, total):\n",
    "        if cluster_pred[i] == 0:\n",
    "            count_0 += 1\n",
    "        elif cluster_pred[i] == 1:\n",
    "            count_1 += 1\n",
    "    \n",
    "    cluster0 = count_0/total\n",
    "    cluster1 = count_1/total\n",
    "    \n",
    "    return cluster0, cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCluster(cluster, test):\n",
    "    neutral, hate = divideTestData(test)\n",
    "    \n",
    "    neutral_pred = cluster.predict(neutral)\n",
    "    hate_pred = cluster.predict(hate)\n",
    "    \n",
    "    nCluster0, nCluster1 = getClusterAvg(neutral_pred)\n",
    "    hCluster0, hCluster1 = getClusterAvg(hate_pred)\n",
    "    \n",
    "    print(\"Neutral Cluster = 0: \" + str(nCluster0))\n",
    "    print(\"Hate Cluster = 1:    \" + str(hCluster1))\n",
    "    print(\" \")\n",
    "    print(\"Neutral Cluster = 1: \" + str(nCluster1))\n",
    "    print(\"Hate Cluster = 0:    \" + str(hCluster0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Unigram Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0.6534719467163086\n"
     ]
    }
   ],
   "source": [
    "k_runi = kCluster(train_runi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.2983508245877061\n",
      "Hate Cluster = 1:    0.856353591160221\n",
      " \n",
      "Neutral Cluster = 1: 0.7016491754122939\n",
      "Hate Cluster = 0:    0.143646408839779\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_runi, test_runi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Bigram Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 1.6098639965057373\n"
     ]
    }
   ],
   "source": [
    "k_rbig = kCluster(train_rbig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.7016491754122939\n",
      "Hate Cluster = 1:    0.143646408839779\n",
      " \n",
      "Neutral Cluster = 1: 0.2983508245877061\n",
      "Hate Cluster = 0:    0.856353591160221\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_rbig, test_rbig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced TFIDF Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 1.149717092514038\n"
     ]
    }
   ],
   "source": [
    "k_rtfidf = kCluster(train_rtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.0022488755622188904\n",
      "Hate Cluster = 1:    0.6621941594317285\n",
      " \n",
      "Neutral Cluster = 1: 0.9977511244377811\n",
      "Hate Cluster = 0:    0.3378058405682715\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_rtfidf, test_rtfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0.8785572052001953\n"
     ]
    }
   ],
   "source": [
    "k_vec = kCluster(train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.4782608695652174\n",
      "Hate Cluster = 1:    0.5169692186266772\n",
      " \n",
      "Neutral Cluster = 1: 0.5217391304347826\n",
      "Hate Cluster = 0:    0.48303078137332284\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_vec, test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 53.41338229179382\n"
     ]
    }
   ],
   "source": [
    "k_uni = kCluster(train_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.7016491754122939\n",
      "Hate Cluster = 1:    0.143646408839779\n",
      " \n",
      "Neutral Cluster = 1: 0.2983508245877061\n",
      "Hate Cluster = 0:    0.856353591160221\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_uni, test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 2734.345181941986\n"
     ]
    }
   ],
   "source": [
    "k_big = kCluster(train_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.7016491754122939\n",
      "Hate Cluster = 1:    0.143646408839779\n",
      " \n",
      "Neutral Cluster = 1: 0.2983508245877061\n",
      "Hate Cluster = 0:    0.856353591160221\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_big, test_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 75.32064080238342\n"
     ]
    }
   ],
   "source": [
    "k_tfidf = kCluster(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Cluster = 0: 0.9985007496251874\n",
      "Hate Cluster = 1:    0.19889502762430938\n",
      " \n",
      "Neutral Cluster = 1: 0.0014992503748125937\n",
      "Hate Cluster = 0:    0.8011049723756906\n"
     ]
    }
   ],
   "source": [
    "evaluateCluster(k_tfidf, test_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
