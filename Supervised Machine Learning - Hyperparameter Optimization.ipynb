{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNLPVectors(folder, filename):\n",
    "    file = folder + '/' + filename + '.npy'\n",
    "    return np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    X_train = loadNLPVectors('train', name)\n",
    "    y_train = loadNLPVectors('train', 'labels')\n",
    "    \n",
    "    X_test = loadNLPVectors('test', name)\n",
    "    y_test = loadNLPVectors('test', 'labels')\n",
    "    \n",
    "    train = [X_train, y_train]\n",
    "    test = [X_test, y_test]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NLP Training/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni, test_uni = loadData('unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big, test_big = loadData('bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf, test_tfidf = loadData('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec, test_vec = loadData('word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_runi, test_runi = loadData('runigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rbig, test_rbig = loadData('rbigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rtfidf, test_rtfidf = loadData('rtfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(folder, clf):\n",
    "    model_path = 'models/' + folder + '/' + clf + '.pkl'\n",
    "    model = joblob.load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Parameters to Tune for Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestHyperparameters():\n",
    "    \n",
    "    n_estimators = [68, 70, 72, 74, 76]\n",
    "    max_depth = [30, 40, 50, 60, 70, 80]\n",
    "    max_depth.append(None)\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 100, num = 10)]\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 100, num = 10)]\n",
    "    \n",
    "    params = {'n_estimators': n_estimators, \n",
    "              'max_depth': max_depth,\n",
    "              'max_features': max_features,\n",
    "              'min_samples_split': min_samples_split, \n",
    "              'min_samples_leaf': min_samples_leaf}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegressionHyperparameters():\n",
    "    \n",
    "    penalty = ['l1', 'l2']\n",
    "    tol = [0.01, 0.001, 0.0001, .00001]\n",
    "    C = np.logspace(0, 4, 10)\n",
    "    max_iter = [int(x) for x in np.linspace(start = 50, stop = 200, num = 15)]\n",
    "    \n",
    "    params = {'penalty': penalty,\n",
    "              'tol': tol,\n",
    "              'C': C,\n",
    "              'max_iter': max_iter}\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupportVectorHyperparameters():\n",
    "    \n",
    "    C = np.logspace(0, 4, 10)\n",
    "    kernel = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "    tol = [0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    params = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'tol': tol}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayesHyperparameters():\n",
    "    \n",
    "    alpha = [x for x in range(0, 11)]\n",
    "    class_prior = [[.1, .9], [.2, .8], [.3, .7], [.4, .6]]\n",
    "    \n",
    "    params = {'alpha': alpha,\n",
    "              'class_prior': class_prior}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Untuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf = loadModel('tfidf', 'rand_forest')\n",
    "rf_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rtfidf = loadModel('rtfidf', 'rand_forest')\n",
    "rf_rtfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_uni = loadModel('uni', 'log_reg')\n",
    "lr_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_big = loadModel('big', 'log_reg')\n",
    "lr_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rbig = loadModel('rbig', 'log_reg')\n",
    "lr_rbig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big = loadModel('big', 'naive_bayes')\n",
    "nb_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model and Parameter Instances for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = RandomForestHyperparameters()\n",
    "lr_params = LogisticRegressionHyperparameters()\n",
    "nb_params = NaiveBayesHyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randGridOptimizer(clf, params, iterations, folds, train):\n",
    "    \n",
    "    tuningGrid = RandomizedSearchCV(estimator = clf,\n",
    "                                    param_distributions = params,\n",
    "                                    n_iter = iterations,\n",
    "                                    scoring = 'accuracy',\n",
    "                                    n_jobs = -1,\n",
    "                                    cv = folds,\n",
    "                                    verbose = 2,\n",
    "                                    random_state = 42)\n",
    "    \n",
    "    best_clf = tuningGrid.fit(train[0], train[1])\n",
    "    \n",
    "    return tuningGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest -TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf_grid = randGridOptimizer(rf_clf, rf_params, 30, 10, train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf_tuned = rf_tfidf_grid.best_estimator_\n",
    "rf_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Reduced TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rtfidf_grid = randGridOptimizer(rf_clf, rf_params, 30, 10, train_rtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rtfidf_tuned = rf_rtfidf_grid.best_estimator_\n",
    "rf_tfidf_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_uni_grid = randGridOptimizer(lr_clf, lr_params, 30, 10, train_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_uni_tuned = lr_uni_grid.best_estimator_\n",
    "lr_uni_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_big_grid = randGridOptimizer(lr_clf, lr_params, 30, 10, train_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_big_tuned = lr_big_grid.best_estimator_\n",
    "lr_big_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Reduced Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rbig_grid = randGridOptimizer(lr_clf, lr_params, 30, 10, train_rbig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rbig_tuned = lr_rbig_grid.best_estimator_\n",
    "lr_rbig_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes - Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big_grid = randGridOptimizer(nb_clf, nb_params, 30, 10, train_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big_tuned = nb_big_grid.best_estimator_\n",
    "nb_big_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned vs Untuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(original, tuned, test, clf_name, nlp_name):\n",
    "    \n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    \n",
    "    y_pred = original.predict(X_test)\n",
    "    y_pred_t = tuned.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    acc_t = accuracy_score(y_test, y_pred_t)\n",
    "    roc_auc_t = roc_auc_score(y_test, y_pred_t)\n",
    "    f1_t = f1_score(y_test, y_pred_t)\n",
    "    precision_t = precision_score(y_test, y_pred_t)\n",
    "    recall_t = recall_score(y_test, y_pred_t)\n",
    "    \n",
    "    print('Untuned ' + clf_name + ' - ' + nlp_name + ' Metrics: ')\n",
    "    print(clf_name + ' Accuracy: ' + str(acc))\n",
    "    print(clf_name + ' ROC AUC Score: '+ str(roc_auc))\n",
    "    print(clf_name + ' F Score: ' + str(f1))\n",
    "    print(clf_name + ' Precision Score: ' + str(precision))\n",
    "    print(clf_name + ' Recall Score ' + str(recall))\n",
    "    print(\" \")\n",
    "    \n",
    "    print('Tuned ' + clf_name + ' - ' + nlp_name + ' Metrics: ')\n",
    "    print(clf_name + ' Accuracy: ' + str(acc_t))\n",
    "    print(clf_name + ' ROC AUC Score: '+ str(roc_auc_t))\n",
    "    print(clf_name + ' F Score: ' + str(f1_t))\n",
    "    print(clf_name + ' Precision Score: ' + str(precision_t))\n",
    "    print(clf_name + ' Recall Score ' + str(recall_t))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest TFIDF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(rf_tfidf, rf_tfidf_tuned, test_tfidf, 'Random Forest', 'TFIDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Reduced TFIDF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(rf_rtfidf, rf_rtfidf_tuned, test_rtfidf, 'Random Forest', 'Reduced TFIDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Unigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lr_uni, lr_uni_tuned, test_uni, 'Logistic Regression', 'Unigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Bigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lr_big, lr_big_tuned, test_big, 'Logistic Regression', 'Bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Reduced Bigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(lr_rbig, lr_rbig_tuned, test_rbig, 'Logistic Regression', 'Reduced Bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Bigram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(nb_big, nb_big_tuned, test_big, 'Naive Bayes', 'Bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "folderpath = path + '/models' + '/tuned'\n",
    "os.mkdir(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, name, test):\n",
    "    filepath = folderpath + '/' + name + '.pkl'\n",
    "    joblib.dump(model, filepath)\n",
    "    \n",
    "    # test to see if model correctly saved\n",
    "    model_load = joblib.load(filepath)\n",
    "    X = test[0]\n",
    "    y = test[1]\n",
    "    \n",
    "    assert model.score(X, y) == model_load.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(rf_tfidf_tuned, 'rf_tfidf', test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Reduced TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(rf_rtfidf_tuned, 'rf_rtfidf', test_rtfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(lr_uni_tuned, 'lr_uni', test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(lr_big_tuned, 'lr_big', test_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Reduced Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(lr_rbig_tuned, 'lr_rbig', test_rbig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(nb_big_tuned, 'nb_big', test_big)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
