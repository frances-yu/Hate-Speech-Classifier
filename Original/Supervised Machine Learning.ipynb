{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(filename):\n",
    "    file = filename\n",
    "    if '.csv' not in filename:\n",
    "        file += '.csv'\n",
    "    data = pd.read_csv(file, encoding = 'ISO-8859-1')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNLPVectors(folder, filename):\n",
    "    file = folder + '/' + filename + '.npy'\n",
    "    return np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    X_train = loadNLPVectors('train', name)\n",
    "    y_train = loadNLPVectors('train', 'labels')\n",
    "    \n",
    "    X_test = loadNLPVectors('test', name)\n",
    "    y_test = loadNLPVectors('test', 'labels')\n",
    "    \n",
    "    train = [X_train, y_train]\n",
    "    test = [X_test, y_test]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"binary_classification\"\n",
    "data = loadCSV(csvFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genClassifiers(filter = []):\n",
    "\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    log_clf = LogisticRegression()\n",
    "    nb_clf = MultinomialNB()\n",
    "    svm_clf = SVC(probability = True)\n",
    "    \n",
    "    classifiers = [rf_clf, log_clf, nb_clf, svm_clf]\n",
    "    names = ['Random Forest', 'Logistic Regression', 'Naive Bayes', 'SVM']\n",
    "    \n",
    "    filtered_classifiers = []\n",
    "    filtered_names = []\n",
    "    for i in range(0, len(classifiers)):\n",
    "        if i not in filter:\n",
    "            filtered_classifiers.append(classifiers[i])\n",
    "            filtered_names.append(names[i])\n",
    "            \n",
    "    return filtered_classifiers, filtered_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf_array, clf_names, train, test):\n",
    "    X_train = train[0]\n",
    "    y_train = train[1]\n",
    "    \n",
    "    X_test = test[0]\n",
    "    y_test = test[1]\n",
    "    \n",
    "    for i in range(0, len(clf_array)):\n",
    "        start = time.time()\n",
    "        clf_array[i].fit(X_train, y_train)\n",
    "        end = time.time() - start\n",
    "        \n",
    "        y_pred = clf_array[i].predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        f_score = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "\n",
    "        print(clf_names[i] + ': Completed in ' + str(end) + ' seconds')\n",
    "        print(clf_names[i] + ' Accuracy: ' + str(accuracy))\n",
    "        print(clf_names[i] + ' ROC AUC Score: ' + str(roc_auc))\n",
    "        print(clf_names[i] + ' F Score: ' + str(f_score))\n",
    "        print(clf_names[i] + ' Precision: ' + str(precision))\n",
    "        print(clf_names[i] + ' Recall: ' + str(recall))\n",
    "        print(\" \")\n",
    "        \n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NLP Training/Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni, test_uni = loadData('unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big, test_big = loadData('bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf, test_tfidf = loadData('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word2vec, test_word2vec = loadData('word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_runi, test_runi = loadData('runigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rbig, test_rbig = loadData('rbigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rtfidf, test_rtfidf = loadData('rtfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced_TFIDF Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtfidf_clf, clf_names = genClassifiers(filter = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 1.5711941719055176 seconds\n",
      "Random Forest Accuracy: 0.6109188773548635\n",
      "Random Forest ROC AUC Score: 0.6154967109973033\n",
      "Random Forest F Score: 0.6651224354731965\n",
      "Random Forest Precision: 0.5726495726495726\n",
      "Random Forest Recall: 0.7932123125493291\n",
      " \n",
      "Logistic Regression: Completed in 0.3475041389465332 seconds\n",
      "Logistic Regression Accuracy: 0.6351403306420608\n",
      "Logistic Regression ROC AUC Score: 0.6361170243607478\n",
      "Logistic Regression F Score: 0.6428302596913812\n",
      "Logistic Regression Precision: 0.6143884892086331\n",
      "Logistic Regression Recall: 0.6740331491712708\n",
      " \n",
      "SVM: Completed in 171.74720120429993 seconds\n",
      "SVM Accuracy: 0.6312956555171088\n",
      "SVM ROC AUC Score: 0.621745165302116\n",
      "SVM F Score: 0.3987460815047022\n",
      "SVM Precision: 0.9695121951219512\n",
      "SVM Recall: 0.2509865824782952\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_rtfidf, y_rtfidf = evaluate(rtfidf_clf, clf_names, train_rtfidf, test_rtfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced_Unigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runi_clf, clf_names = genClassifiers(filter = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 1.3853070735931396 seconds\n",
      "Random Forest Accuracy: 0.6974240676662822\n",
      "Random Forest ROC AUC Score: 0.6969952277215773\n",
      "Random Forest F Score: 0.6865790521704499\n",
      "Random Forest Precision: 0.6929260450160771\n",
      "Random Forest Recall: 0.6803472770323599\n",
      " \n",
      "Logistic Regression: Completed in 0.4902491569519043 seconds\n",
      "Logistic Regression Accuracy: 0.6981930026912726\n",
      "Logistic Regression ROC AUC Score: 0.6974079061495299\n",
      "Logistic Regression F Score: 0.6828282828282828\n",
      "Logistic Regression Precision: 0.6995033112582781\n",
      "Logistic Regression Recall: 0.6669297553275454\n",
      " \n",
      "SVM: Completed in 105.41624212265015 seconds\n",
      "SVM Accuracy: 0.7370242214532872\n",
      "SVM ROC AUC Score: 0.7341540358471119\n",
      "SVM F Score: 0.6976127320954907\n",
      "SVM Precision: 0.792964824120603\n",
      "SVM Recall: 0.6227308602999211\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_runi, y_runi = evaluate(runi_clf, clf_names, train_runi, test_runi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced_Bigram Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbig_clf, clf_names = genClassifiers(filter = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 2.163566827774048 seconds\n",
      "Random Forest Accuracy: 0.6662821991541714\n",
      "Random Forest ROC AUC Score: 0.6663975628602432\n",
      "Random Forest F Score: 0.661993769470405\n",
      "Random Forest Precision: 0.6533435818601077\n",
      "Random Forest Recall: 0.6708760852407262\n",
      " \n",
      "Logistic Regression: Completed in 1.2324132919311523 seconds\n",
      "Logistic Regression Accuracy: 0.6720492118415994\n",
      "Logistic Regression ROC AUC Score: 0.6715440622230321\n",
      "Logistic Regression F Score: 0.6594810379241516\n",
      "Logistic Regression Precision: 0.6672051696284329\n",
      "Logistic Regression Recall: 0.6519337016574586\n",
      " \n",
      "SVM: Completed in 266.23683619499207 seconds\n",
      "SVM Accuracy: 0.6916570549788543\n",
      "SVM ROC AUC Score: 0.6865170414003732\n",
      "SVM F Score: 0.606090373280943\n",
      "SVM Precision: 0.8023407022106632\n",
      "SVM Recall: 0.48697711128650356\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_rbig, y_rbig = evaluate(rbig_clf, clf_names, train_rbig, test_rbig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_clf, clf_names = genClassifiers(filter = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 0.3986940383911133 seconds\n",
      "Random Forest Accuracy: 0.5974625144175317\n",
      "Random Forest ROC AUC Score: 0.6004358712514303\n",
      "Random Forest F Score: 0.6340440405452639\n",
      "Random Forest Precision: 0.56900878293601\n",
      "Random Forest Recall: 0.7158642462509865\n",
      " \n",
      "Logistic Regression: Completed in 0.24937009811401367 seconds\n",
      "Logistic Regression Accuracy: 0.5797770088427527\n",
      "Logistic Regression ROC AUC Score: 0.5806574810463749\n",
      "Logistic Regression F Score: 0.5877027536778575\n",
      "Logistic Regression Precision: 0.5628612716763006\n",
      "Logistic Regression Recall: 0.6148382004735596\n",
      " \n",
      "SVM: Completed in 102.85331630706787 seconds\n",
      "SVM Accuracy: 0.5786236063052672\n",
      "SVM ROC AUC Score: 0.5783438194083701\n",
      "SVM F Score: 0.5674822415153907\n",
      "SVM Precision: 0.5674822415153907\n",
      "SVM Recall: 0.5674822415153907\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_vec, y_vec = evaluate(vec_clf, clf_names, train_word2vec, test_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw TFIDF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_clf, clf_names = genClassifiers(filter = [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 10.230072021484375 seconds\n",
      "Random Forest Accuracy: 0.9042675893886967\n",
      "Random Forest ROC AUC Score: 0.9031634537900742\n",
      "Random Forest F Score: 0.8974886784685056\n",
      "Random Forest Precision: 0.9380378657487092\n",
      "Random Forest Recall: 0.8602999210734017\n",
      " \n",
      "Logistic Regression: Completed in 0.16809797286987305 seconds\n",
      "Logistic Regression Accuracy: 0.9081122645136486\n",
      "Logistic Regression ROC AUC Score: 0.9066539145581115\n",
      "Logistic Regression F Score: 0.9001253656498119\n",
      "Logistic Regression Precision: 0.9564831261101243\n",
      "Logistic Regression Recall: 0.8500394632991318\n",
      " \n",
      "Naive Bayes: Completed in 0.2786829471588135 seconds\n",
      "Naive Bayes Accuracy: 0.8565936178392926\n",
      "Naive Bayes ROC AUC Score: 0.8566470513756539\n",
      "Naive Bayes F Score: 0.8536681051392702\n",
      "Naive Bayes Precision: 0.8486739469578783\n",
      "Naive Bayes Recall: 0.8587213891081295\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_tfidf, y_tfidf = evaluate(tfidf_clf, clf_names, train_tfidf, test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Unigram Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_clf, clf_names = genClassifiers(filter = [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 8.68398904800415 seconds\n",
      "Random Forest Accuracy: 0.9023452518262207\n",
      "Random Forest ROC AUC Score: 0.9017452599667019\n",
      "Random Forest F Score: 0.8975806451612904\n",
      "Random Forest Precision: 0.9175597691673537\n",
      "Random Forest Recall: 0.8784530386740331\n",
      " \n",
      "Logistic Regression: Completed in 0.8870952129364014 seconds\n",
      "Logistic Regression Accuracy: 0.9158016147635525\n",
      "Logistic Regression ROC AUC Score: 0.9147844191558522\n",
      "Logistic Regression F Score: 0.9101354123922856\n",
      "Logistic Regression Precision: 0.9478632478632478\n",
      "Logistic Regression Recall: 0.8752959747434885\n",
      " \n",
      "Naive Bayes: Completed in 0.8655989170074463 seconds\n",
      "Naive Bayes Accuracy: 0.8673587081891581\n",
      "Naive Bayes ROC AUC Score: 0.8676571343373302\n",
      "Naive Bayes F Score: 0.8659152739992227\n",
      "Naive Bayes Precision: 0.8529862174578867\n",
      "Naive Bayes Recall: 0.8792423046566693\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_uni, y_uni = evaluate(uni_clf, clf_names, train_uni, test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Bigram Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_clf, clf_names = genClassifiers(filter = [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Completed in 60.024255990982056 seconds\n",
      "Random Forest Accuracy: 0.8900422914263745\n",
      "Random Forest ROC AUC Score: 0.8884827515208458\n",
      "Random Forest F Score: 0.8800335570469798\n",
      "Random Forest Precision: 0.9391226499552372\n",
      "Random Forest Recall: 0.8279400157853196\n",
      " \n",
      "Logistic Regression: Completed in 17.185407161712646 seconds\n",
      "Logistic Regression Accuracy: 0.9142637447135717\n",
      "Logistic Regression ROC AUC Score: 0.913186066792965\n",
      "Logistic Regression F Score: 0.9082682023858494\n",
      "Logistic Regression Precision: 0.9484536082474226\n",
      "Logistic Regression Recall: 0.8713496448303079\n",
      " \n",
      "Naive Bayes: Completed in 20.337838172912598 seconds\n",
      "Naive Bayes Accuracy: 0.8777393310265282\n",
      "Naive Bayes ROC AUC Score: 0.8779158171506195\n",
      "Naive Bayes F Score: 0.87578125\n",
      "Naive Bayes Precision: 0.8669760247486465\n",
      "Naive Bayes Recall: 0.8847671665351223\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_big, y_big = evaluate(big_clf, clf_names, train_big, test_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "folderpath = path + \"/models\"\n",
    "os.mkdir(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModels(features, feature_names, classifiers, X_array, y_array):\n",
    "    for i in range(0, len(features)):\n",
    "        feat = features[i]\n",
    "        os.mkdir(folderpath + feature_names[i])\n",
    "        for j in range(0, len(classifiers)):\n",
    "            clas = feat[j]\n",
    "            filepath = folderpath + feature_names[i] + classifiers[j] + \".pkl\"\n",
    "            joblib.dump(clas, filepath)\n",
    "            \n",
    "            # test to see if models correctly saved\n",
    "            clas_load = joblib.load(filepath)\n",
    "            X = X_array[i]\n",
    "            y = y_array[i]\n",
    "            \n",
    "            assert clas.score(X, y) == clas_load.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list1 = [rtfidf_clf, runi_clf, rbig_clf, vec_clf]\n",
    "f_list2 = [tfidf_clf, uni_clf, big_clf]\n",
    "\n",
    "fname_list1 = [\"/rtfidf\", \"/runi\", \"/rbig\", \"/word2vec\"]\n",
    "fname_list2 = [\"/tfidf\", \"/uni\", \"/big\"]\n",
    "\n",
    "c_list1 = [\"/rand_forest\", \"/log_reg\", \"/svm\"]\n",
    "c_list2 = [\"/rand_forest\", \"/log_reg\", \"/naive_bayes\"]\n",
    "\n",
    "fx_list1 = [x_rtfidf, x_runi, x_rbig, x_vec]\n",
    "fy_list1 = [y_rtfidf, y_runi, y_rbig, y_vec]\n",
    "\n",
    "fx_list2 = [x_tfidf, x_uni, x_big]\n",
    "fy_list2 = [y_tfidf, y_uni, y_big]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModels(f_list1, fname_list1, c_list1, fx_list1, fy_list1)\n",
    "saveModels(f_list2, fname_list2, c_list2, fx_list2, fy_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
